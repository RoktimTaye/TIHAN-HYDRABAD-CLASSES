{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## NLP Basics & Tokenization\n",
        "\n",
        "Topics Covered\n",
        "\n",
        "Text Cleaning\n",
        "\n",
        "Tokenization\n",
        "\n",
        "Vocabulary Building\n",
        "\n",
        "Intro to Word Embeddings"
      ],
      "metadata": {
        "id": "qOVinxIjyVRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is NLP?\n",
        "\n",
        "\n",
        "**Natural Language Processing (NLP)** is a field of AI that helps computers understand, interpret, and generate human language.\n",
        "\n",
        "### Examples:\n",
        "- Chatbots\n",
        "- Google Search\n",
        "- Spam Detection\n",
        "- Sentiment Analysis\n",
        "- Language Translation"
      ],
      "metadata": {
        "id": "RVzV674eym6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Humans understand text naturally, but computers only understand numbers.\n",
        "So the central challenge of NLP is:\n",
        "\n",
        "How do we convert human language into numbers without losing meaning?"
      ],
      "metadata": {
        "id": "-1ProD7RvjaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why NLP Basics & Tokenization Matter\n",
        "(Text Cleaning, Tokenization, Vocabulary Building, Word Embeddings)\n",
        "\n",
        "Why NLP Needs These Steps\n",
        "\n",
        "Computers do not understand language the way humans do.\n",
        "They only understand numbers.\n",
        "\n",
        "The goal of Natural Language Processing (NLP) is to convert human language into numerical representations that machines can process without losing meaning."
      ],
      "metadata": {
        "id": "kbrNXC2Kv_eS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZPUhxqK4wBzs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzMVBUDpyBJG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Natural Language Processing (NLP) enables computers to understand human language.\n",
        "NLP is used in chatbots, search engines, and voice assistants!\n",
        "\"\"\"\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv0IMQ8gy24r",
        "outputId": "8828da3e-34ba-419b-d7b5-4504513595a6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Natural Language Processing (NLP) enables computers to understand human language.\n",
            "NLP is used in chatbots, search engines, and voice assistants!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tote1kFj10aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Cleaning\n",
        "\n",
        "Why clean text?\n",
        "- Remove noise (punctuation, symbols)\n",
        "- Make text consistent\n",
        "- Improve model performance\n",
        "\n",
        "Common steps:\n",
        "- Lowercasing\n",
        "- Removing punctuation\n",
        "- Removing extra spaces\n"
      ],
      "metadata": {
        "id": "kj1fRTqmy83s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If text is not cleaned:\n",
        "\n",
        "1. the same word looks different to the computer\n",
        "\n",
        "2. models learn incorrect or noisy patterns\n",
        "\n",
        "Text cleaning makes language consistent, so models focus on meaning, not formatting noise."
      ],
      "metadata": {
        "id": "ZUbOWERTwL4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()                      # lowercase\n",
        "    # Why needed?\n",
        "    # NLP models treat \"NLP\" and \"nlp\" as different words,Lowercasing avoids duplicate vocabulary entries\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)     # remove punctuation\n",
        "    # Removes everything except: lowercase letters (aâ€“z),spaces (\\s)\n",
        "    text = re.sub(r'\\s+', ' ', text)         # remove extra spaces\n",
        "    # Why needed?\n",
        "    # Extra spaces can create empty tokens during tokenization,Clean spacing ensures accurate word splitting\n",
        "    return text.strip() # Removes spaces at the start and end of the text\n",
        "\n",
        "cleaned_text = clean_text(text)\n",
        "print(cleaned_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSwHhubny56X",
        "outputId": "e9d1dbe5-190f-404d-9a3c-b21e94a9cdfb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "natural language processing nlp enables computers to understand human language nlp is used in chatbots search engines and voice assistants\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n",
        "\n",
        "Tokenization = breaking text into smaller units (tokens)\n",
        "\n",
        "Example:\n",
        "\"I like NLP\" â†’ [\"i\", \"like\", \"nlp\"]\n"
      ],
      "metadata": {
        "id": "XCZ2s_ObzRBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machines cannot process long text directly.\n",
        "They need text to be split into smaller units called tokens.\n",
        "\n",
        "Tokenization:\n",
        "\n",
        "1. breaks sentences into words or subwords\n",
        "\n",
        "2. defines what the model considers a basic unit of language\n",
        "\n",
        "Without tokenization:\n",
        "\n",
        "1. counting words is impossible\n",
        "\n",
        "2. learning patterns is impossible"
      ],
      "metadata": {
        "id": "TxAPcQiawTCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = cleaned_text.split()\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsc7PWYIzMje",
        "outputId": "d155b22e-f157-4ad3-ed8f-913ed64aebb2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'processing', 'nlp', 'enables', 'computers', 'to', 'understand', 'human', 'language', 'nlp', 'is', 'used', 'in', 'chatbots', 'search', 'engines', 'and', 'voice', 'assistants']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Types of Tokenization**\n",
        "\n",
        "1. Word Tokenization\n",
        "[\"I\", \"love\", \"NLP\"]\n",
        "\n",
        "Simple\n",
        "\n",
        "Fails for: punctuation and unknown words\n",
        "\n",
        "2. Sentence Tokenization\n",
        "\"I love NLP. It is fun.\"\n",
        "â†’ [\"I love NLP.\", \"It is fun.\"]\n",
        "\n",
        "Used in:\n",
        "summarization\n",
        "document processing\n",
        "\n",
        "3. Subword Tokenization\n",
        "\"unhappiness\" â†’ [\"un\", \"happy\", \"ness\"]\n",
        "\n",
        "Used in:\n",
        "BERT,\n",
        "GPT,\n",
        "modern LLMs\n",
        "\n",
        "Handles: rare words, new words\n",
        "\n",
        "Why tokenization matters\n",
        "\n",
        "Different tokenization â†’ different models performance\n",
        "\n",
        "Example:\n",
        "\n",
        "\"New York\"\n",
        "\n",
        "Word tokens â†’ [\"New\", \"York\"]\n",
        "\n",
        "Phrase token â†’ [\"New_York\"]"
      ],
      "metadata": {
        "id": "Tz9F8KJWsp7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why Computers Need Tokenization\n",
        "```text\n",
        "A computer:\n",
        "\n",
        "âŒ Cannot understand sentences\n",
        "âŒ Cannot understand grammar or meaning\n",
        "âœ… Can only work with numbers\n",
        "\n",
        "So we follow this pipeline:\n",
        "\n",
        "Text â†’ Tokens â†’ Numbers â†’ Model\n",
        "```\n",
        "\n",
        "Tokenization is required because NLP models cannot process raw text. Tokenization breaks text into smaller units (tokens), which helps in vocabulary creation, numerical representation, frequency analysis, and learning semantic meaning. It is a fundamental preprocessing step in NLP."
      ],
      "metadata": {
        "id": "8mWj4gIm89DT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vocabulary Building\n",
        "\n",
        "Vocabulary = unique words in the dataset\n",
        "\n",
        "Used to:\n",
        "- Assign IDs to words\n",
        "- Convert text into numbers\n"
      ],
      "metadata": {
        "id": "WAYUcZ0T0KVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After tokenization, words are still strings, not numbers.\n",
        "\n",
        "Vocabulary building:\n",
        "\n",
        "1. assigns a unique numerical ID to each word\n",
        "\n",
        "2. creates a mapping from words â†’ numbers\n",
        "\n",
        "This step makes text machine-readable."
      ],
      "metadata": {
        "id": "ANkKjnrMwda1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(tokens))\n",
        "# set(tokens): Removes duplicate words then sorted Sorts words alphabetically\n",
        "\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "# Why do this? Converts words â†’ numbers, Enables numerical representation of text,\n",
        "# Used in embeddings, BoW, TF-IDF, deep learning\n",
        "index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
        "# Why needed? Convert model output back to text\n",
        "# Useful in:Text generation, Decoding predictions, Chatbots\n",
        "print(\"Vocabulary:\", vocab)\n",
        "print(\"\\nWord â†’ Index mapping:\")\n",
        "word_to_index\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnWrHRUG0ID_",
        "outputId": "4ad388f7-2d35-40e9-cf0b-6bf967579974"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['and', 'assistants', 'chatbots', 'computers', 'enables', 'engines', 'human', 'in', 'is', 'language', 'natural', 'nlp', 'processing', 'search', 'to', 'understand', 'used', 'voice']\n",
            "\n",
            "Word â†’ Index mapping:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 0,\n",
              " 'assistants': 1,\n",
              " 'chatbots': 2,\n",
              " 'computers': 3,\n",
              " 'enables': 4,\n",
              " 'engines': 5,\n",
              " 'human': 6,\n",
              " 'in': 7,\n",
              " 'is': 8,\n",
              " 'language': 9,\n",
              " 'natural': 10,\n",
              " 'nlp': 11,\n",
              " 'processing': 12,\n",
              " 'search': 13,\n",
              " 'to': 14,\n",
              " 'understand': 15,\n",
              " 'used': 16,\n",
              " 'voice': 17}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Concept         | Why                       |\n",
        "| --------------- | ------------------------- |\n",
        "| Vocabulary      | Defines known words       |\n",
        "| Word IDs        | Required for ML/DL models |\n",
        "| Reverse mapping | Decode predictions        |\n",
        "| Consistency     | Same word â†’ same number   |\n"
      ],
      "metadata": {
        "id": "9rJaoRqs_-Af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Frequency\n",
        "\n",
        "Helps understand:\n",
        "- Important words\n",
        "- Common vs rare words\n"
      ],
      "metadata": {
        "id": "07Xb70Vm0dqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq = Counter(tokens)\n",
        "word_freq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYtSqoPb0bD-",
        "outputId": "2f47080b-a4c8-4040-88df-281e411fe762"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'natural': 1,\n",
              "         'language': 2,\n",
              "         'processing': 1,\n",
              "         'nlp': 2,\n",
              "         'enables': 1,\n",
              "         'computers': 1,\n",
              "         'to': 1,\n",
              "         'understand': 1,\n",
              "         'human': 1,\n",
              "         'is': 1,\n",
              "         'used': 1,\n",
              "         'in': 1,\n",
              "         'chatbots': 1,\n",
              "         'search': 1,\n",
              "         'engines': 1,\n",
              "         'and': 1,\n",
              "         'voice': 1,\n",
              "         'assistants': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text â†’ Numbers (Bag of Words)\n",
        "\n",
        "Each sentence is represented by word counts.\n",
        "\n",
        "This is the simplest numerical representation.\n"
      ],
      "metadata": {
        "id": "L0J4WZSu2Kk4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of Words (BoW) represents text as:\n",
        "\n",
        "A vector of numbers\n",
        "\n",
        "Each number = count of a word in the vocabulary\n",
        "\n",
        "ðŸ‘‰ Order of words is ignored\n",
        "\n",
        "ðŸ‘‰ Only frequency matters"
      ],
      "metadata": {
        "id": "bJa0JSTSAeQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vector = np.zeros(len(vocab))\n",
        "\n",
        "for word in tokens:# Loop runs once per word in the text.\n",
        "    bow_vector[word_to_index[word]] += 1\n",
        "    # word_to_index[word] finds the index of the word\n",
        "    # That index position in bow_vector is increased by 1\n",
        "\n",
        "print(\"Bag of Words Vector:\\n\", bow_vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b0HcL192Gvb",
        "outputId": "24d61ffa-02ff-4a93-bb76-a70ee5e59112"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words Vector:\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Bag of Words is Limited\n",
        "\n",
        "###  Limitations of Bag of Words\n",
        "\n",
        "- Ignores word order  \n",
        "- No meaning captured  \n",
        "- Large vocabulary â†’ large vectors  \n",
        "```text\n",
        "Example:\n",
        "\"nlp is fun\"\n",
        "\"fun is nlp\"\n",
        "Both give the same BoW vector\n",
        "```\n",
        "\n",
        "\n",
        "This leads to TF-IDF and Word Embeddings\n"
      ],
      "metadata": {
        "id": "6A1loF0Q3xyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embeddings\n",
        "\n",
        "Word embeddings represent **words as dense vectors** that capture meaning.\n",
        "\n",
        "Examples:\n",
        "- king âˆ’ man + woman â‰ˆ queen\n",
        "- Words with similar meaning have similar vectors\n",
        "\n",
        "\n",
        "- movie is good\n",
        "\n",
        "- film is excellent\n",
        "\n",
        "BoW â†’ treats them differently\n",
        "Embeddings â†’ understand they are similar\n",
        "\n",
        "\n",
        "\n",
        "Popular methods:\n",
        "- Word2Vec\n",
        "- GloVe\n",
        "- FastText\n"
      ],
      "metadata": {
        "id": "uud88Z-f4DNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These vectors help models learn:\n",
        "\n",
        "Meaning\n",
        "\n",
        "Similarity\n",
        "\n",
        "Relationships between words"
      ],
      "metadata": {
        "id": "Y1i-NYh2CyhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Static\t                 Contextual\n",
        "\n",
        "Word2Vec\t                BERT, GPT\n",
        "\n",
        "One vector                   per word\tDifferent vectors per context\n",
        "\n",
        "Cannot handle polysemy\t  Handles meaning changes"
      ],
      "metadata": {
        "id": "IusUzhTe9riy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding Dimension Trade-off\n",
        "\n",
        "Low dimension â†’ less expressive\n",
        "\n",
        "High dimension â†’ slower, overfitting\n",
        "\n",
        "Practical ranges (50â€“300)"
      ],
      "metadata": {
        "id": "iBYqtM0z97R4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-trained vs Train-from-Scratch Embeddings\n",
        "\n",
        "Most real-world NLP uses pre-trained embeddings.\n",
        "\n",
        "Word2Vec / GloVe / FastText\n",
        "\n",
        "Transfer learning"
      ],
      "metadata": {
        "id": "P-nnubm7-JvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 5\n",
        "# Each word will be represented by 5 numbers\n",
        "# These numbers are the features of the word\n",
        "# Think of each dimension as a hidden property:\n",
        "# topic\n",
        "# sentiment\n",
        "# grammatical role\n",
        "# etc.\n",
        "# In real models: 50, 100, 300, 768 dimensions are common\n",
        "# Here we use 5 for easy understanding\n",
        "\n",
        "\n",
        "# This is a dictionary comprehension.\n",
        "# For each word in vocab:\n",
        "# Generate a random vector of length embedding_dim\n",
        "# Store it as:word â†’ vector\n",
        "embeddings = {\n",
        "    word: np.random.rand(embedding_dim)\n",
        "    for word in vocab\n",
        "}\n",
        "\n",
        "for word, vec in embeddings.items():\n",
        "    print(word, \"â†’\", vec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv-mxqzV3thY",
        "outputId": "162a9fc4-2ad0-4f51-d53e-50e774090fbc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and â†’ [0.31568878 0.03297298 0.78598979 0.99964606 0.99851803]\n",
            "assistants â†’ [0.69695969 0.20778194 0.49317771 0.4184829  0.49290862]\n",
            "chatbots â†’ [0.7274954  0.87505508 0.24577654 0.77713533 0.97318989]\n",
            "computers â†’ [0.98338286 0.46039405 0.32969101 0.4396318  0.03949881]\n",
            "enables â†’ [0.35904872 0.06148977 0.3814664  0.3766486  0.89924155]\n",
            "engines â†’ [0.14341834 0.90007705 0.68314038 0.60958044 0.76874129]\n",
            "human â†’ [0.01160788 0.94044877 0.67269997 0.51048854 0.86883029]\n",
            "in â†’ [0.08996756 0.16892612 0.40992155 0.36665449 0.0360421 ]\n",
            "is â†’ [0.25182055 0.87059747 0.59753374 0.09393537 0.70966218]\n",
            "language â†’ [0.88692195 0.73939    0.66933445 0.53259825 0.67531008]\n",
            "natural â†’ [0.18177754 0.11229565 0.46711316 0.0114562  0.33281834]\n",
            "nlp â†’ [0.41094168 0.90708845 0.25976883 0.51274198 0.36771205]\n",
            "processing â†’ [0.5984755  0.11131554 0.68943983 0.7280334  0.58560835]\n",
            "search â†’ [0.02387958 0.59636598 0.36800773 0.65013249 0.26444204]\n",
            "to â†’ [0.8500861  0.85513018 0.54452359 0.59802752 0.6391237 ]\n",
            "understand â†’ [0.52821005 0.10269972 0.5599941  0.30378367 0.3752822 ]\n",
            "used â†’ [0.93059433 0.70059613 0.84041757 0.95617344 0.63260585]\n",
            "voice â†’ [0.24143524 0.22253567 0.65687774 0.61404905 0.30593719]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important Note:\n",
        "\n",
        "These vectors are random\n",
        "\n",
        "They do not carry meaning yet\n",
        "\n",
        "Used only for demonstration"
      ],
      "metadata": {
        "id": "ym1qjB-MDgM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Real embeddings are learned using:\n",
        "\n",
        "Word2Vec\n",
        "\n",
        "GloVe\n",
        "\n",
        "FastText\n",
        "\n",
        "BERT"
      ],
      "metadata": {
        "id": "9tk2Waz_8dqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Similarity Idea\n",
        "\n",
        "Using embeddings:\n",
        "\n",
        "similar words â†’ similar vectors\n",
        "\n",
        "\n",
        "Example:\n",
        "\n",
        "king âˆ’ man + woman â‰ˆ queen\n",
        "\n",
        "\n",
        "This is possible only with embeddings."
      ],
      "metadata": {
        "id": "XbtYaAdNEZ96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embeddings represent words as dense numerical vectors of fixed size. They capture semantic and syntactic relationships between words and are used as inputs to NLP models instead of sparse representations like Bag of Words.\n",
        "\n",
        "The training algorithm (model) creates the embeddings automatically, not a human and not by manual rules."
      ],
      "metadata": {
        "id": "TpsAEnfTEoPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Word Similarity\n",
        "\n",
        "We compare embeddings using distance (cosine similarity).\n",
        "\n",
        "Closer vectors â†’ similar meaning\n"
      ],
      "metadata": {
        "id": "2pBQxOrP4OWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(v1, v2):# v1 and v2 are word embeddings\n",
        "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "    # Dot Product (Numerator),Larger dot product = vectors point in similar direction\n",
        "    # Vector Length (Denominator)\n",
        "    # Measures angle between vectors\n",
        "\n",
        "\n",
        "\n",
        "word1, word2 = \"nlp\", \"language\" # Two words whose similarity we want to check\n",
        "similarity = cosine_similarity(embeddings[word1], embeddings[word2])# Fetch embedding vectors & Compute cosine similarity\n",
        "print(f\"Similarity between '{word1}' and '{word2}':\", similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXq4lxJH4LRI",
        "outputId": "75ebaa12-f039-4737-dda0-ffdadd593adf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'nlp' and 'language': 0.9028090551160789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a.b = ||a||.||b||cos Î¸"
      ],
      "metadata": {
        "id": "1AFd7LXwCSRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why cosine similarity for NLP?\n",
        "\n",
        "In NLP:\n",
        "\n",
        "We care about direction of meaning\n",
        "\n",
        "Not absolute magnitude of vectors\n",
        "\n",
        "Two words can be similar even if:\n",
        "\n",
        "One appears more often\n",
        "\n",
        "One has larger values"
      ],
      "metadata": {
        "id": "gc6C39SHrLOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dot product measures how much two vectors point in the same direction.\n",
        "\n",
        "Larger value â†’ vectors are more aligned"
      ],
      "metadata": {
        "id": "XFBO7cE-rtlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity compares the meaning of words by measuring the angle between their embedding vectors, not their size."
      ],
      "metadata": {
        "id": "32rusolbsCDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Similarity | Interpretation |\n",
        "| ---------- | -------------- |\n",
        "| 0.9 â€“ 1.0  | Very similar   |\n",
        "| 0.6 â€“ 0.8  | Related        |\n",
        "| 0.3 â€“ 0.5  | Weak relation  |\n",
        "| â‰ˆ 0        | Unrelated      |\n"
      ],
      "metadata": {
        "id": "i7dUmj-MGwYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```text\n",
        "Why Cosine Similarity Is Preferred\n",
        "\n",
        "âœ”ï¸ Ignores vector magnitude\n",
        "âœ”ï¸ Focuses on direction (meaning)\n",
        "âœ”ï¸ Works well for high-dimensional data\n",
        "âœ”ï¸ Widely used in NLP, IR, recommender systems\n",
        "```"
      ],
      "metadata": {
        "id": "Wu58QOXeG0AO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our demo, embeddings are random, so similarity has no real meaning."
      ],
      "metadata": {
        "id": "dCf5BC8aGtiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Mini Activity\n",
        "\n",
        "1. Add your own paragraph as text  \n",
        "2. Clean it  \n",
        "3. Tokenize it  \n",
        "4. Build vocabulary  \n",
        "5. Print word frequencies  \n",
        "\n",
        "ðŸ’¡ Bonus:\n",
        "- Try removing stopwords manually\n"
      ],
      "metadata": {
        "id": "PGKsKUCg4XqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real Embedding example using Word2Vec"
      ],
      "metadata": {
        "id": "DfeIeOp984rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt8lX8xr89YL",
        "outputId": "06d50153-b07e-488d-eb68-78c4e3d393b9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n"
      ],
      "metadata": {
        "id": "6R0rDeRV8_aA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example corpus (list of sentences)\n",
        "sentences = [\n",
        "    \"nlp is fun\",\n",
        "    \"nlp is powerful\",\n",
        "    \"language processing is part of ai\",\n",
        "    \"ai and nlp are related\",\n",
        "    \"deep learning helps nlp\",\n",
        "    \"language models learn meaning\"\n",
        "]\n",
        "\n",
        "# Tokenize each sentence\n",
        "tokenized_sentences = [s.split() for s in sentences]\n",
        "tokenized_sentences\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Icfd4hQR9Amp",
        "outputId": "db678600-e1c0-4091-ae11-f6499b49c40b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['nlp', 'is', 'fun'],\n",
              " ['nlp', 'is', 'powerful'],\n",
              " ['language', 'processing', 'is', 'part', 'of', 'ai'],\n",
              " ['ai', 'and', 'nlp', 'are', 'related'],\n",
              " ['deep', 'learning', 'helps', 'nlp'],\n",
              " ['language', 'models', 'learn', 'meaning']]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(\n",
        "    sentences=tokenized_sentences,\n",
        "    vector_size=50,    # embedding dimension\n",
        "    window=3,          # context window size\n",
        "    min_count=1,       # include all words\n",
        "    workers=2,\n",
        "    epochs=100\n",
        ")\n"
      ],
      "metadata": {
        "id": "h3HZaqD49dA7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why window matters:\n",
        "\n",
        "Small window â†’ syntactic similarity\n",
        "\n",
        "Large window â†’ semantic similarity"
      ],
      "metadata": {
        "id": "rRGzOOchpy8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Real Word Embeddings"
      ],
      "metadata": {
        "id": "nGs_Y74U9vjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get embedding vector for a word\n",
        "nlp_vector = w2v_model.wv[\"nlp\"]\n",
        "language_vector = w2v_model.wv[\"language\"]\n",
        "\n",
        "print(\"NLP vector shape:\", nlp_vector.shape)\n",
        "print(\"NLP vector:\", nlp_vector[:10])  # show first 10 values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyFcg3xa9ggY",
        "outputId": "afa5c5ac-8fc9-4e3b-eaed-d8c14b603356"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP vector shape: (50,)\n",
            "NLP vector: [-0.0012096   0.00046292  0.01025917  0.01807347 -0.01862075 -0.01429455\n",
            "  0.01299328  0.01796793 -0.01021279 -0.0076134 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These vectors are learned, not random\n",
        "\n",
        "Shape (50,) â†’ 50-dimensional embedding"
      ],
      "metadata": {
        "id": "d9N96VlU9pig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = w2v_model.wv.similarity(\"nlp\", \"language\")\n",
        "print(\"Similarity between 'nlp' and 'language':\", similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9bD4kk_9iVj",
        "outputId": "f5c95f21-ef5a-4d49-8a5d-de9855cec141"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'nlp' and 'language': -0.013799454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "\n",
        "Higher value â†’ words appear in similar contexts\n",
        "\n"
      ],
      "metadata": {
        "id": "VQJIQaM-927G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Most Similar Words"
      ],
      "metadata": {
        "id": "rU0ScCzW9-M1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(\"nlp\", topn=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5_REaa090am",
        "outputId": "70e51ad4-a886-4dda-e0e4-c350e893971a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('part', 0.21584632992744446),\n",
              " ('are', 0.17368143796920776),\n",
              " ('of', 0.15688852965831757),\n",
              " ('helps', 0.1364484578371048),\n",
              " ('ai', 0.1354638636112213),\n",
              " ('deep', 0.10196870565414429),\n",
              " ('powerful', 0.0623539574444294),\n",
              " ('is', 0.0527440682053566),\n",
              " ('fun', 0.050736211240291595),\n",
              " ('and', 0.043769653886556625)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q) Do we manually assign vectors?\n",
        "\n",
        "A) No, the model learns them automatically.\n",
        "-----------------------------\n",
        "Q) Why similar words become close?\n",
        "\n",
        "A) Because they receive similar gradient updates from similar contexts.\n",
        "-----------------------------\n",
        "Q) Is this supervised learning?\n",
        "\n",
        "A) No, it is self-supervised / unsupervised.\n",
        "\n",
        "-----------------------------"
      ],
      "metadata": {
        "id": "h8qsGDLvqFTS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OkON4q6y96No"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}