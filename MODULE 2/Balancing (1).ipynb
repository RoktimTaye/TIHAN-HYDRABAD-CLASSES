{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g5cjUSZh1cld"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iqte5LAM3bbD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fXfJJxfN3fPD"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours, ClusterCentroids\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vFLdspy63coC"
      },
      "outputs": [],
      "source": [
        "from scipy.stats.mstats import winsorize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "3WGPdPJbAhFz",
        "outputId": "9beac9f0-ee3d-49a9-eec9-f0c6fd73c426"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kRp1MJz3k5c",
        "outputId": "edd0d557-aeb5-49e6-9bb5-64e5b863956e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender   Age  \\\n",
            "0          1    15634602  Hargrave        619.0    France  Female  42.0   \n",
            "1          2    15647311      Hill        608.0     Spain  Female  41.0   \n",
            "2          3    15619304      Onio        502.0    France  Female  42.0   \n",
            "3          4    15701354      Boni        699.0    France  Female  39.0   \n",
            "4          5    15737888  Mitchell        850.0     Spain  Female  43.0   \n",
            "\n",
            "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
            "0     2.0       0.00            1.0        1.0             1.0   \n",
            "1     1.0   83807.86            1.0        0.0             1.0   \n",
            "2     8.0  159660.80            3.0        1.0             0.0   \n",
            "3     1.0       0.00            2.0        0.0             0.0   \n",
            "4     2.0  125510.82            1.0        NaN             1.0   \n",
            "\n",
            "   EstimatedSalary  Exited  \n",
            "0        101348.88       1  \n",
            "1        112542.58       0  \n",
            "2        113931.57       1  \n",
            "3         93826.63       0  \n",
            "4         79084.10       0  \n"
          ]
        }
      ],
      "source": [
        "# Step 2: Load Data\n",
        "\n",
        "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwmH_ftE9Vj_",
        "outputId": "36339ea4-5d02-4efe-8d28-8e605a56e632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exited\n",
            "0    0.796241\n",
            "1    0.203759\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(df['Exited'].value_counts(normalize=True))  # checking imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QnDbyk9T33nb"
      },
      "outputs": [],
      "source": [
        "# Step 3: Select Features & Target\n",
        "\n",
        "# Drop non-useful columns\n",
        "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "pdkJMDvq9anX",
        "outputId": "4c05a9ee-c04c-4632-d37b-c6d243af7fc2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore   Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0        619.0  42.0     2.0       0.00            1.0        1.0   \n",
              "1        608.0  41.0     1.0   83807.86            1.0        0.0   \n",
              "2        502.0  42.0     8.0  159660.80            3.0        1.0   \n",
              "3        699.0  39.0     1.0       0.00            2.0        0.0   \n",
              "4        850.0  43.0     2.0  125510.82            1.0        NaN   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
              "0             1.0        101348.88       1              False   \n",
              "1             1.0        112542.58       0              False   \n",
              "2             0.0        113931.57       1              False   \n",
              "3             0.0         93826.63       0              False   \n",
              "4             1.0         79084.10       0              False   \n",
              "\n",
              "   Geography_Spain  Gender_Male  \n",
              "0            False        False  \n",
              "1             True        False  \n",
              "2            False        False  \n",
              "3            False        False  \n",
              "4             True        False  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Encode categorical variables (simple get_dummies)\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChcMQrnP4Rrz",
        "outputId": "77c00055-0a25-4eb2-aa57-6bb44518b1a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature shape: (10002, 11)\n"
          ]
        }
      ],
      "source": [
        "X = df.drop(\"Exited\", axis=1)\n",
        "y = df[\"Exited\"]\n",
        "\n",
        "print(\"Feature shape:\", X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TdRdm5M7yJB"
      },
      "source": [
        "Winsorizing\n",
        "\n",
        "* Problem it solves:\n",
        "\n",
        "  Sometimes outliers are too extreme and may harm the   model even after scaling.\n",
        "\n",
        "  Example: a few customers with unrealistic Balance   values (like 10× larger than typical).\n",
        "\n",
        "* What it does:\n",
        "\n",
        "  Instead of removing rows, caps extreme values at  certain percentiles.\n",
        "\n",
        "  Example: 1st percentile → values below this are set   to that percentile value.\n",
        "\n",
        "  99th percentile → values above this are capped at   that level.\n",
        "\n",
        "* When to use:\n",
        "\n",
        "  When you don’t want to drop records but still need  to reduce outlier impact.\n",
        "  \n",
        "  Safer than deleting rows since you keep all data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UmOy1le4wTB",
        "outputId": "d0d747ef-58fd-4481-edca-925ef8088451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before winsorization:\n",
            "       CreditScore        Balance  EstimatedSalary\n",
            "count  9998.000000   10000.000000     10002.000000\n",
            "mean    650.522404   76481.519210    100083.331145\n",
            "std      96.647651   62393.568682     57508.117802\n",
            "min     350.000000       0.000000        11.580000\n",
            "25%     584.000000       0.000000     50983.750000\n",
            "50%     652.000000   97198.540000    100185.240000\n",
            "75%     718.000000  127644.240000    149383.652500\n",
            "max     850.000000  250898.090000    199992.480000\n",
            "NaN count before filling: 19\n",
            "After winsorization:\n",
            "        CreditScore        Balance  EstimatedSalary\n",
            "count  10002.000000   10002.000000     10002.000000\n",
            "mean     650.816537   76391.117164    100082.672288\n",
            "std       96.172932   62188.054457     57475.059449\n",
            "min      432.000000       0.000000      1843.240000\n",
            "25%      584.000000       0.000000     50983.750000\n",
            "50%      652.000000   97221.520000    100185.240000\n",
            "75%      718.000000  127653.825000    149383.652500\n",
            "max      850.000000  186347.970000    198069.710000\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Winsorizing\n",
        "\n",
        "# Applying winsorization to selected numeric columns\n",
        "print(\"Before winsorization:\")\n",
        "print(X[['CreditScore', 'Balance', 'EstimatedSalary']].describe())\n",
        "\n",
        "# Fix winsorize output (convert masked array -> normal array)\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "for col in ['CreditScore', 'Balance', 'EstimatedSalary']:\n",
        "    X[col] = winsorize(X[col], limits=[0.01, 0.01]).data  # use .data to avoid NaN\n",
        "\n",
        "# After all transformations, check for NaNs\n",
        "print(\"NaN count before filling:\", X.isna().sum().sum())\n",
        "\n",
        "# Fill any remaining NaNs (safe fallback)\n",
        "X = X.fillna(0)\n",
        "\n",
        "\n",
        "print(\"After winsorization:\")\n",
        "print(X[['CreditScore', 'Balance', 'EstimatedSalary']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPjfJlkG7nFD"
      },
      "source": [
        " Robust Scaling\n",
        "\n",
        "* Problem it solves:\n",
        "\n",
        "  Features like Balance or Salary can have extreme   values (outliers).\n",
        "  \n",
        "  Standard scaling (z-score) and MinMax scaling get    heavily affected by outliers → pulling the scale   too much.\n",
        "  \n",
        "* What it does:\n",
        "\n",
        "  Instead of using mean and standard deviation  (sensitive to outliers), RobustScaler uses:\n",
        "\n",
        "  Median (central point)\n",
        "\n",
        "  Interquartile range (IQR = Q3 − Q1) (spread of  middle 50%)\n",
        "\n",
        "  So outliers don’t distort the scaling.\n",
        "\n",
        "* Robust Scaling Formula\n",
        "\n",
        "  For a feature \\( x \\):\n",
        "\n",
        "  $\n",
        "  x' = \\frac{x - \\text{median}(x)}{\\text{IQR}(x)}\n",
        "  $\n",
        "\n",
        "  where:\n",
        "\n",
        "  - $ \\text{median}(x) $ = 50th percentile (middle value)  \n",
        "  - $ \\text{IQR}(x) = Q_3 - Q_1 $ = difference between 75th percentile (Q3) and 25th percentile (Q1)\n",
        "\n",
        "* When to use:\n",
        "\n",
        "  When dataset has skewed distributions or many  outliers.\n",
        "\n",
        "  E.g., in churn data, one customer may have an   extremely high balance compared to others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOlWLgjnE6pP"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vKj8NjXO478_"
      },
      "outputs": [],
      "source": [
        "# Step 5: Robust Scaling\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPAj1uPi5JVM",
        "outputId": "a8a99464-e4d9-4841-82a4-1f2ba9aefb26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaled data sample:\n",
            "   CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
            "0    -0.246269  0.416667   -0.75 -0.761603            0.0        0.0   \n",
            "1    -0.328358  0.333333   -1.00 -0.105078            0.0       -1.0   \n",
            "2    -1.119403  0.416667    0.75  0.489130            2.0        0.0   \n",
            "3     0.350746  0.166667   -1.00 -0.761603            1.0       -1.0   \n",
            "4     1.477612  0.500000   -0.75  0.221609            0.0       -1.0   \n",
            "\n",
            "   IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
            "0             0.0         0.011826                0.0              0.0   \n",
            "1             0.0         0.125583                0.0              1.0   \n",
            "2            -1.0         0.139699                0.0              0.0   \n",
            "3            -1.0        -0.064620                0.0              0.0   \n",
            "4             0.0        -0.214443                0.0              1.0   \n",
            "\n",
            "   Gender_Male  \n",
            "0         -1.0  \n",
            "1         -1.0  \n",
            "2         -1.0  \n",
            "3         -1.0  \n",
            "4         -1.0  \n"
          ]
        }
      ],
      "source": [
        "print(\"Scaled data sample:\")\n",
        "print(X_scaled.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXLkHQlU8GRe",
        "outputId": "37486792-1fc2-4350-d8a0-3b25be7df618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:\n",
            " [  1   2   3   4 100]\n",
            "Robust Scaled:\n",
            " [-1.  -0.5  0.   0.5 48.5]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "data = np.array([[1], [2], [3], [4], [100]])\n",
        "\n",
        "scaler = RobustScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(\"Original:\\n\", data.flatten())\n",
        "print(\"Robust Scaled:\\n\", scaled_data.flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXwTUYEN5J13",
        "outputId": "b1ab2019-3b82-460f-a51d-86ecc90519d0"
      },
      "outputs": [],
      "source": [
        "# Step 6: Train-Test Split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1DD8Bym5NUz",
        "outputId": "22256e9d-90b9-4453-97a8-97cdd5d5d1ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution [5574 1427]\n",
            "Baseline Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89      2390\n",
            "           1       0.61      0.19      0.29       611\n",
            "\n",
            "    accuracy                           0.81      3001\n",
            "   macro avg       0.71      0.58      0.59      3001\n",
            "weighted avg       0.78      0.81      0.77      3001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Baseline Model (Without Resampling)\n",
        "print(\"Class distribution\", np.bincount(y_train))\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Baseline Results:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et-ssguo8PYu"
      },
      "source": [
        "**Handling Class Imbalance (Undersampling / OverSampling)**\n",
        "\n",
        "* Problem it solves:\n",
        "\n",
        "  In churn prediction (like our dataset), usually:\n",
        "  \n",
        "  80–90% customers stay (Exited=0)\n",
        "  \n",
        "  10–20% churn (Exited=1)\n",
        "  \n",
        "  A model trained on this will just predict “No   churn” most of the time → high accuracy, but  useless for detecting churners.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TEq8yCf9_N3"
      },
      "source": [
        "\n",
        "\n",
        "* **Undersampling**: Reduce majority class (e.g., keep only 10k “No churn” customers to match 2k “Churn” ones).\n",
        "\n",
        "  Fast, simple\n",
        "  \n",
        "  Risk of losing important majority data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIpTwcxq5UFK",
        "outputId": "8532c904-6cf7-49e8-a1fe-1f54e9e3d611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution after random undersampling: [1427 1427]\n",
            "Undersampling Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.71      0.79      2390\n",
            "           1       0.38      0.72      0.50       611\n",
            "\n",
            "    accuracy                           0.71      3001\n",
            "   macro avg       0.65      0.71      0.65      3001\n",
            "weighted avg       0.80      0.71      0.73      3001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Random Undersampling\n",
        "\n",
        "undersample = RandomUnderSampler(random_state=42)\n",
        "X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after random undersampling:\", np.bincount(y_train_under))\n",
        "\n",
        "clf.fit(X_train_under, y_train_under)\n",
        "y_pred_under = clf.predict(X_test)\n",
        "\n",
        "print(\"Undersampling Results:\")\n",
        "print(classification_report(y_test, y_pred_under))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZejZ1Q9YUA4O"
      },
      "source": [
        "### Tomek Links (Undersampling)\n",
        "\n",
        "- A **Tomek Link** is a pair of samples:\n",
        "  - They belong to **different classes** (e.g., churned vs not churned).\n",
        "  - They are **each other’s nearest neighbor**.\n",
        "\n",
        "- These pairs usually occur at the **class boundary** where overlap or confusion exists.\n",
        "\n",
        "- **How it works:**\n",
        "  - Identify Tomek Link pairs.\n",
        "  - Remove the **majority class sample** from each pair.\n",
        "  - This cleans the boundary and reduces class overlap.\n",
        "\n",
        "Benefit: Unlike random undersampling, Tomek Links remove only the **problematic majority samples** that confuse the classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX1nx94eUFuz",
        "outputId": "63f37ce3-2c68-4f42-c8c0-f6d8b6beef36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution after TomekLinks undersampling: [5214 1427]\n",
            "Undersampling Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.89      2390\n",
            "           1       0.58      0.25      0.35       611\n",
            "\n",
            "    accuracy                           0.81      3001\n",
            "   macro avg       0.71      0.60      0.62      3001\n",
            "weighted avg       0.78      0.81      0.78      3001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TomekLinks Undersampling\n",
        "\n",
        "TL_undersample = TomekLinks(sampling_strategy=\"auto\")\n",
        "X_train_TL, y_train_TL = TL_undersample.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after TomekLinks undersampling:\", np.bincount(y_train_TL))\n",
        "\n",
        "clf.fit(X_train_TL, y_train_TL)\n",
        "y_pred_TL = clf.predict(X_test)\n",
        "\n",
        "print(\"Undersampling Results:\")\n",
        "print(classification_report(y_test, y_pred_TL))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mICtizj5Vwix"
      },
      "source": [
        "### Edited Nearest Neighbors (ENN) Undersampling\n",
        "\n",
        "- **Idea:** ENN removes **noisy samples** that don’t agree with their neighbors.  \n",
        "- For each data point, check its *k nearest neighbors* (commonly k=3).  \n",
        "- If the point’s class label is **different from the majority of its neighbors**, it is considered noise and removed.  \n",
        "\n",
        "**Benefit:**  \n",
        "- Cleans the dataset by removing mislabeled or out-of-place points.  \n",
        "- Helps classifiers build clearer decision boundaries.  \n",
        "\n",
        "**Note:**  \n",
        "- ENN can remove **both majority and minority samples**, unlike Tomek Links which usually remove only majority samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff8iK-6rV829",
        "outputId": "78b7e1cb-32bf-4bd9-b9e9-ba05ed193300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution after ENN undersampling: [3970 1427]\n",
            "Undersampling Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88      2390\n",
            "           1       0.52      0.47      0.49       611\n",
            "\n",
            "    accuracy                           0.80      3001\n",
            "   macro avg       0.69      0.68      0.69      3001\n",
            "weighted avg       0.80      0.80      0.80      3001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ENN Undersampling\n",
        "\n",
        "ENN_undersample = EditedNearestNeighbours()\n",
        "X_train_ENN, y_train_ENN = ENN_undersample.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after ENN undersampling:\", np.bincount(y_train_ENN))\n",
        "\n",
        "clf.fit(X_train_ENN, y_train_ENN)\n",
        "y_pred_ENN = clf.predict(X_test)\n",
        "\n",
        "print(\"Undersampling Results:\")\n",
        "print(classification_report(y_test, y_pred_ENN))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhzzJsudODeh"
      },
      "source": [
        "**Random Over Sampler:** Random oversampling randomly chooses minority samples (with replacement) and adds duplicates until class counts match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7-fANBQNmkd",
        "outputId": "871b6b26-d6b1-4825-a930-d3888da0eae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution after Random Over Sampler: [5574 5574]\n",
            "Random Over Sampler Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.71      0.79      2390\n",
            "           1       0.38      0.71      0.50       611\n",
            "\n",
            "    accuracy                           0.71      3001\n",
            "   macro avg       0.64      0.71      0.65      3001\n",
            "weighted avg       0.80      0.71      0.73      3001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ROS = RandomOverSampler(random_state=42)\n",
        "X_train_ros, y_train_ros = ROS.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after Random Over Sampler:\", np.bincount(y_train_ros))\n",
        "\n",
        "clf.fit(X_train_ros, y_train_ros)\n",
        "y_pred_ros = clf.predict(X_test)\n",
        "\n",
        "print(\"Random Over Sampler Results:\")\n",
        "print(classification_report(y_test, y_pred_ros))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlsP6EWm-DbQ"
      },
      "source": [
        "### SMOTE (Synthetic Minority Oversampling Technique)\n",
        "\n",
        "- **Idea:** Instead of duplicating minority samples (like Random Oversampling), SMOTE creates **synthetic samples**.\n",
        "- **How it works:**\n",
        "  1. For each minority sample, find its *k nearest minority neighbors* (default k=5).\n",
        "  2. Randomly choose one neighbor.\n",
        "  3. Create a synthetic sample **between the two points** by interpolation.\n",
        "- **Result:** The minority class grows with *new, artificial points* that are not exact copies.\n",
        "\n",
        " **Benefit:** Reduces overfitting (compared to simple duplication).  \n",
        " **Limitation:** Can generate samples in regions where classes overlap → may introduce noise.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U3Ujo2o6_4p",
        "outputId": "b5875c94-6c87-4dcc-a3c8-aaaea8d5f53d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution after SMOTE: [5574 5574]\n",
            "SMOTE Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.71      0.79      2390\n",
            "           1       0.38      0.71      0.50       611\n",
            "\n",
            "    accuracy                           0.71      3001\n",
            "   macro avg       0.64      0.71      0.65      3001\n",
            "weighted avg       0.80      0.71      0.73      3001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SMOTE Oversampling\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after SMOTE:\", np.bincount(y_train_smote))\n",
        "\n",
        "clf.fit(X_train_smote, y_train_smote)\n",
        "y_pred_smote = clf.predict(X_test)\n",
        "\n",
        "print(\"SMOTE Results:\")\n",
        "print(classification_report(y_test, y_pred_smote))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay9jMg5zX81r"
      },
      "source": [
        "### Borderline-SMOTE\n",
        "\n",
        "- **Idea:** A smarter version of SMOTE that only generates synthetic samples for **minority points near the decision boundary**.\n",
        "- **How it works:**\n",
        "  1. Identify minority samples whose neighbors are **mostly majority class** → these are \"borderline\" points.\n",
        "  2. Generate synthetic samples **around these borderline cases**.\n",
        "- **Result:** Focuses oversampling where it matters most: the **class boundary**.\n",
        "\n",
        "**Benefit:** Strengthens the classifier in the hardest-to-learn region (the boundary).  \n",
        "**Limitation:** May overfit borderline noise if the boundary is very fuzzy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xr3Iuu-XmXT",
        "outputId": "2043ecf1-9cf5-4e2b-868a-cf0a8359619c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution after BL SMOTE: [5574 5574]\n",
            "BL SMOTE Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.68      0.78      2390\n",
            "           1       0.37      0.73      0.49       611\n",
            "\n",
            "    accuracy                           0.69      3001\n",
            "   macro avg       0.64      0.71      0.64      3001\n",
            "weighted avg       0.80      0.69      0.72      3001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#BorderlineSMOTE\n",
        "\n",
        "BLsmote = BorderlineSMOTE(random_state=42)\n",
        "X_train_blsmote, y_train_blsmote = BLsmote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after BL SMOTE:\", np.bincount(y_train_blsmote))\n",
        "\n",
        "clf.fit(X_train_blsmote, y_train_blsmote)\n",
        "y_pred_blsmote = clf.predict(X_test)\n",
        "\n",
        "print(\"BL SMOTE Results:\")\n",
        "print(classification_report(y_test, y_pred_blsmote))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8lOaPma-GLl"
      },
      "source": [
        "* When to use:\n",
        "\n",
        "  Whenever target variable distribution is skewed   (imbalanced).\n",
        "  \n",
        "  Critical in classification tasks like fraud   detection, churn prediction, medical diagnosis."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
