{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5cjUSZh1cld"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqte5LAM3bbD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXfJJxfN3fPD"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours, ClusterCentroids\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFLdspy63coC"
      },
      "outputs": [],
      "source": [
        "from scipy.stats.mstats import winsorize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "3WGPdPJbAhFz",
        "outputId": "9beac9f0-ee3d-49a9-eec9-f0c6fd73c426"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kRp1MJz3k5c",
        "outputId": "edd0d557-aeb5-49e6-9bb5-64e5b863956e"
      },
      "outputs": [],
      "source": [
        "# Step 2: Load Data\n",
        "\n",
        "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwmH_ftE9Vj_",
        "outputId": "36339ea4-5d02-4efe-8d28-8e605a56e632"
      },
      "outputs": [],
      "source": [
        "print(df['Exited'].value_counts(normalize=True))  # checking imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnDbyk9T33nb"
      },
      "outputs": [],
      "source": [
        "# Step 3: Select Features & Target\n",
        "# Drop non-useful columns\n",
        "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "pdkJMDvq9anX",
        "outputId": "4c05a9ee-c04c-4632-d37b-c6d243af7fc2"
      },
      "outputs": [],
      "source": [
        "# Encode categorical variables (simple get_dummies)\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChcMQrnP4Rrz",
        "outputId": "77c00055-0a25-4eb2-aa57-6bb44518b1a8"
      },
      "outputs": [],
      "source": [
        "X = df.drop(\"Exited\", axis=1)\n",
        "y = df[\"Exited\"]\n",
        "\n",
        "print(\"Feature shape:\", X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TdRdm5M7yJB"
      },
      "source": [
        "Winsorizing\n",
        "\n",
        "* Problem it solves:\n",
        "\n",
        "  Sometimes outliers are too extreme and may harm the   model even after scaling.\n",
        "\n",
        "  Example: a few customers with unrealistic Balance   values (like 10× larger than typical).\n",
        "\n",
        "* What it does:\n",
        "\n",
        "  Instead of removing rows, caps extreme values at  certain percentiles.\n",
        "\n",
        "  Example: 1st percentile → values below this are set   to that percentile value.\n",
        "\n",
        "  99th percentile → values above this are capped at   that level.\n",
        "\n",
        "* When to use:\n",
        "\n",
        "  When you don’t want to drop records but still need  to reduce outlier impact.\n",
        "  \n",
        "  Safer than deleting rows since you keep all data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UmOy1le4wTB",
        "outputId": "d0d747ef-58fd-4481-edca-925ef8088451"
      },
      "outputs": [],
      "source": [
        "# Step 4: Winsorizing\n",
        "\n",
        "# Applying winsorization to selected numeric columns\n",
        "print(\"Before winsorization:\")\n",
        "print(X[['CreditScore', 'Balance', 'EstimatedSalary']].describe())\n",
        "\n",
        "# Fix winsorize output (convert masked array -> normal array)\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "for col in ['CreditScore', 'Balance', 'EstimatedSalary']:\n",
        "    X[col] = winsorize(X[col], limits=[0.01, 0.01]).data  # use .data to avoid NaN\n",
        "\n",
        "# After all transformations, check for NaNs\n",
        "print(\"NaN count before filling:\", X.isna().sum().sum())\n",
        "\n",
        "# Fill any remaining NaNs (safe fallback)\n",
        "X = X.fillna(0)\n",
        "\n",
        "\n",
        "print(\"After winsorization:\")\n",
        "print(X[['CreditScore', 'Balance', 'EstimatedSalary']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPjfJlkG7nFD"
      },
      "source": [
        " Robust Scaling\n",
        "\n",
        "* Problem it solves:\n",
        "\n",
        "  Features like Balance or Salary can have extreme   values (outliers).\n",
        "  \n",
        "  Standard scaling (z-score) and MinMax scaling get    heavily affected by outliers → pulling the scale   too much.\n",
        "  \n",
        "* What it does:\n",
        "\n",
        "  Instead of using mean and standard deviation  (sensitive to outliers), RobustScaler uses:\n",
        "\n",
        "  Median (central point)\n",
        "\n",
        "  Interquartile range (IQR = Q3 − Q1) (spread of  middle 50%)\n",
        "\n",
        "  So outliers don’t distort the scaling.\n",
        "\n",
        "* Robust Scaling Formula\n",
        "\n",
        "  For a feature \\( x \\):\n",
        "\n",
        "  $\n",
        "  x' = \\frac{x - \\text{median}(x)}{\\text{IQR}(x)}\n",
        "  $\n",
        "\n",
        "  where:\n",
        "\n",
        "  - $ \\text{median}(x) $ = 50th percentile (middle value)  \n",
        "  - $ \\text{IQR}(x) = Q_3 - Q_1 $ = difference between 75th percentile (Q3) and 25th percentile (Q1)\n",
        "\n",
        "* When to use:\n",
        "\n",
        "  When dataset has skewed distributions or many  outliers.\n",
        "\n",
        "  E.g., in churn data, one customer may have an   extremely high balance compared to others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOlWLgjnE6pP"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKj8NjXO478_"
      },
      "outputs": [],
      "source": [
        "# Step 5: Robust Scaling\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPAj1uPi5JVM",
        "outputId": "a8a99464-e4d9-4841-82a4-1f2ba9aefb26"
      },
      "outputs": [],
      "source": [
        "print(\"Scaled data sample:\")\n",
        "print(X_scaled.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXLkHQlU8GRe",
        "outputId": "37486792-1fc2-4350-d8a0-3b25be7df618"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "data = np.array([[1], [2], [3], [4], [100]])\n",
        "\n",
        "scaler = RobustScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(\"Original:\\n\", data.flatten())\n",
        "print(\"Robust Scaled:\\n\", scaled_data.flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXwTUYEN5J13",
        "outputId": "b1ab2019-3b82-460f-a51d-86ecc90519d0"
      },
      "outputs": [],
      "source": [
        "# Step 6: Train-Test Split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1DD8Bym5NUz",
        "outputId": "22256e9d-90b9-4453-97a8-97cdd5d5d1ac"
      },
      "outputs": [],
      "source": [
        "# Step 7: Baseline Model (Without Resampling)\n",
        "print(\"Class distribution\", np.bincount(y_train))\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Baseline Results:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et-ssguo8PYu"
      },
      "source": [
        "**Handling Class Imbalance (Undersampling / OverSampling)**\n",
        "\n",
        "* Problem it solves:\n",
        "\n",
        "  In churn prediction (like our dataset), usually:\n",
        "  \n",
        "  80–90% customers stay (Exited=0)\n",
        "  \n",
        "  10–20% churn (Exited=1)\n",
        "  \n",
        "  A model trained on this will just predict “No   churn” most of the time → high accuracy, but  useless for detecting churners.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TEq8yCf9_N3"
      },
      "source": [
        "\n",
        "\n",
        "* **Undersampling**: Reduce majority class (e.g., keep only 10k “No churn” customers to match 2k “Churn” ones).\n",
        "\n",
        "  Fast, simple\n",
        "  \n",
        "  Risk of losing important majority data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIpTwcxq5UFK",
        "outputId": "8532c904-6cf7-49e8-a1fe-1f54e9e3d611"
      },
      "outputs": [],
      "source": [
        "# Random Undersampling\n",
        "\n",
        "undersample = RandomUnderSampler(random_state=42)\n",
        "X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after random undersampling:\", np.bincount(y_train_under))\n",
        "\n",
        "clf.fit(X_train_under, y_train_under)\n",
        "y_pred_under = clf.predict(X_test)\n",
        "\n",
        "print(\"Undersampling Results:\")\n",
        "print(classification_report(y_test, y_pred_under))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZejZ1Q9YUA4O"
      },
      "source": [
        "### Tomek Links (Undersampling)\n",
        "\n",
        "- A **Tomek Link** is a pair of samples:\n",
        "  - They belong to **different classes** (e.g., churned vs not churned).\n",
        "  - They are **each other’s nearest neighbor**.\n",
        "\n",
        "- These pairs usually occur at the **class boundary** where overlap or confusion exists.\n",
        "\n",
        "- **How it works:**\n",
        "  - Identify Tomek Link pairs.\n",
        "  - Remove the **majority class sample** from each pair.\n",
        "  - This cleans the boundary and reduces class overlap.\n",
        "\n",
        "Benefit: Unlike random undersampling, Tomek Links remove only the **problematic majority samples** that confuse the classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX1nx94eUFuz",
        "outputId": "63f37ce3-2c68-4f42-c8c0-f6d8b6beef36"
      },
      "outputs": [],
      "source": [
        "# TomekLinks Undersampling\n",
        "\n",
        "TL_undersample = TomekLinks(sampling_strategy=\"auto\")\n",
        "X_train_TL, y_train_TL = TL_undersample.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after TomekLinks undersampling:\", np.bincount(y_train_TL))\n",
        "\n",
        "clf.fit(X_train_TL, y_train_TL)\n",
        "y_pred_TL = clf.predict(X_test)\n",
        "\n",
        "print(\"Undersampling Results:\")\n",
        "print(classification_report(y_test, y_pred_TL))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mICtizj5Vwix"
      },
      "source": [
        "### Edited Nearest Neighbors (ENN) Undersampling\n",
        "\n",
        "- **Idea:** ENN removes **noisy samples** that don’t agree with their neighbors.  \n",
        "- For each data point, check its *k nearest neighbors* (commonly k=3).  \n",
        "- If the point’s class label is **different from the majority of its neighbors**, it is considered noise and removed.  \n",
        "\n",
        "**Benefit:**  \n",
        "- Cleans the dataset by removing mislabeled or out-of-place points.  \n",
        "- Helps classifiers build clearer decision boundaries.  \n",
        "\n",
        "**Note:**  \n",
        "- ENN can remove **both majority and minority samples**, unlike Tomek Links which usually remove only majority samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff8iK-6rV829",
        "outputId": "78b7e1cb-32bf-4bd9-b9e9-ba05ed193300"
      },
      "outputs": [],
      "source": [
        "# ENN Undersampling\n",
        "\n",
        "ENN_undersample = EditedNearestNeighbours()\n",
        "X_train_ENN, y_train_ENN = ENN_undersample.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after ENN undersampling:\", np.bincount(y_train_ENN))\n",
        "\n",
        "clf.fit(X_train_ENN, y_train_ENN)\n",
        "y_pred_ENN = clf.predict(X_test)\n",
        "\n",
        "print(\"Undersampling Results:\")\n",
        "print(classification_report(y_test, y_pred_ENN))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhzzJsudODeh"
      },
      "source": [
        "**Random Over Sampler:** Random oversampling randomly chooses minority samples (with replacement) and adds duplicates until class counts match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7-fANBQNmkd",
        "outputId": "871b6b26-d6b1-4825-a930-d3888da0eae5"
      },
      "outputs": [],
      "source": [
        "ROS = RandomOverSampler(random_state=42)\n",
        "X_train_ros, y_train_ros = ROS.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after Random Over Sampler:\", np.bincount(y_train_ros))\n",
        "\n",
        "clf.fit(X_train_ros, y_train_ros)\n",
        "y_pred_ros = clf.predict(X_test)\n",
        "\n",
        "print(\"Random Over Sampler Results:\")\n",
        "print(classification_report(y_test, y_pred_ros))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlsP6EWm-DbQ"
      },
      "source": [
        "### SMOTE (Synthetic Minority Oversampling Technique)\n",
        "\n",
        "- **Idea:** Instead of duplicating minority samples (like Random Oversampling), SMOTE creates **synthetic samples**.\n",
        "- **How it works:**\n",
        "  1. For each minority sample, find its *k nearest minority neighbors* (default k=5).\n",
        "  2. Randomly choose one neighbor.\n",
        "  3. Create a synthetic sample **between the two points** by interpolation.\n",
        "- **Result:** The minority class grows with *new, artificial points* that are not exact copies.\n",
        "\n",
        " **Benefit:** Reduces overfitting (compared to simple duplication).  \n",
        " **Limitation:** Can generate samples in regions where classes overlap → may introduce noise.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U3Ujo2o6_4p",
        "outputId": "b5875c94-6c87-4dcc-a3c8-aaaea8d5f53d"
      },
      "outputs": [],
      "source": [
        "# SMOTE Oversampling\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after SMOTE:\", np.bincount(y_train_smote))\n",
        "\n",
        "clf.fit(X_train_smote, y_train_smote)\n",
        "y_pred_smote = clf.predict(X_test)\n",
        "\n",
        "print(\"SMOTE Results:\")\n",
        "print(classification_report(y_test, y_pred_smote))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay9jMg5zX81r"
      },
      "source": [
        "### Borderline-SMOTE\n",
        "\n",
        "- **Idea:** A smarter version of SMOTE that only generates synthetic samples for **minority points near the decision boundary**.\n",
        "- **How it works:**\n",
        "  1. Identify minority samples whose neighbors are **mostly majority class** → these are \"borderline\" points.\n",
        "  2. Generate synthetic samples **around these borderline cases**.\n",
        "- **Result:** Focuses oversampling where it matters most: the **class boundary**.\n",
        "\n",
        "**Benefit:** Strengthens the classifier in the hardest-to-learn region (the boundary).  \n",
        "**Limitation:** May overfit borderline noise if the boundary is very fuzzy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xr3Iuu-XmXT",
        "outputId": "2043ecf1-9cf5-4e2b-868a-cf0a8359619c"
      },
      "outputs": [],
      "source": [
        "#BorderlineSMOTE\n",
        "\n",
        "BLsmote = BorderlineSMOTE(random_state=42)\n",
        "X_train_blsmote, y_train_blsmote = BLsmote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution after BL SMOTE:\", np.bincount(y_train_blsmote))\n",
        "\n",
        "clf.fit(X_train_blsmote, y_train_blsmote)\n",
        "y_pred_blsmote = clf.predict(X_test)\n",
        "\n",
        "print(\"BL SMOTE Results:\")\n",
        "print(classification_report(y_test, y_pred_blsmote))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8lOaPma-GLl"
      },
      "source": [
        "* When to use:\n",
        "\n",
        "  Whenever target variable distribution is skewed   (imbalanced).\n",
        "  \n",
        "  Critical in classification tasks like fraud   detection, churn prediction, medical diagnosis."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
